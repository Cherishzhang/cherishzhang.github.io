<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on Learn and record</title>
    <link>http://cherishzhang.github.io/tags/spark/index.xml</link>
    <description>Recent content in Spark on Learn and record</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="http://cherishzhang.github.io/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Spark之RDD</title>
      <link>http://cherishzhang.github.io/post/spark/sparkRDD/</link>
      <pubDate>Sat, 20 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>http://cherishzhang.github.io/post/spark/sparkRDD/</guid>
      <description>

&lt;h3 id=&#34;rdd&#34;&gt;RDD&lt;/h3&gt;

&lt;p&gt;RDD，全称为Resilient Distributed Datasets（弹性分布式数据集）。简单接触了spark后，萌发了想要深入且透彻的了解RDD到底是什么。&lt;/p&gt;

&lt;p&gt;从英文解释来看，它应该是Dataset的集合，且是一个提供了许多操作接口的数据集合。和普通数据集的区别是：&lt;r&gt;实际数据分布存储在一批机器的内存或硬盘中&lt;/r&gt;。当然RDD还有容错和并行的功能。&lt;/p&gt;

&lt;p&gt;下面摘录了一段对RDD的解释：&lt;/p&gt;

&lt;p&gt;&lt;sg&gt;它是一个&lt;strong&gt;容错&lt;/strong&gt;且&lt;strong&gt;并行&lt;/strong&gt;的数据结构，可以让用户&lt;strong&gt;显式&lt;/strong&gt;地将数据存储到磁盘和内存中，并能控制数据的&lt;strong&gt;分区&lt;/strong&gt;。它只能基于在稳定物理存储中的数据集和其他已有的RDD上执行确定性操作(transformation)来创建。&lt;/sg&gt;&lt;/p&gt;

&lt;p&gt;所以RDD的两个关键点为：带操作接口的数据集，分布式。&lt;/p&gt;

&lt;p&gt;举个例子：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;//读取文件创建RDD
val rdd = sc.textFile(&amp;quot;README.md&amp;quot;).cache()
val numAs = rdd.filter(line =&amp;gt; line.contains(&amp;quot;a&amp;quot;)).count()//包含a的行数
val numBs = rdd.filter(line =&amp;gt; line.contains(&amp;quot;b&amp;quot;)).count()//包含b的行数
println(&amp;quot;Lines with a: %s, Lines with b: %s&amp;quot;.format(numAs, numBs))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;由此可见，RDD&lt;r&gt;本质&lt;/r&gt;是一个&lt;r&gt;只读的分区记录集合&lt;/r&gt;。一个RDD包含多个分区，每个分区是一个dataset片段。&lt;/p&gt;

&lt;p&gt;前面提到了带操作接口的数据集，操作接口主要是RDD提供了对数据进行映射，归一等操作的API接口。这无疑方便了对分布式环境中的数据整合操作。操作分为两类：转换(transformations)和行动(actions)。前者根据原有的RDD创建一个新的RDD，后者则操作结果返回给driver。&lt;/p&gt;

&lt;p&gt;以前总是不理解操作分成两类的原因，直接每次操作后都返回结果不可以么？解释是这样的，首先考虑到有些操作(如filter)过后，返回结果的数据量较大，而有些操作(如count)过后，返回的结果却很简洁。spark设计时，将转换操作设置为lazy的，即不会立即计算结果，只有遇到action，才会处理并返回结果。这样会使spark更高效。&lt;/p&gt;

&lt;p&gt;转换类的操作有：map, filter, flatMap, mapPartitions, mapPartitionsWithIndex, sample, union, intersection, distinct, groupByKey, reduceByKey, aggregateByKey, sortByKey, join, cogroup, cartesian, pipe, coalesce, repartition。&lt;/p&gt;

&lt;p&gt;行动类的操作有：reduce, collect, count, first, take, takeSample, takeOrdered, saveAsTextFile, saveAsSequenceFile, saveAsObjectFile&lt;/p&gt;

&lt;p&gt;相关操作函数如下表：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;val rdd1 = sc.parallelize(1 to 9, 3)
val rdd2 = sc.parallelize(list(&amp;quot;dog&amp;quot;,&amp;quot;tiger&amp;quot;,&amp;quot;lion&amp;quot;,&amp;quot;cat&amp;quot;,&amp;quot;parther&amp;quot;,&amp;quot;eagle&amp;quot;),2)
val rdd3 = sc.parallelize(List(1,2),(3,4),(3,6)))
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;函数名&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;输入与输出&lt;/th&gt;
&lt;th&gt;Code&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;map&lt;/td&gt;
&lt;td&gt;对RDD中的每个元素执行一个指定的函数来产生一个新的RDD，映射函数的参数为RDD中的每一个元素&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;一对一&lt;/td&gt;
&lt;td&gt;val a = rdd1.map(x =&amp;gt; x*2)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;mapValues&lt;/td&gt;
&lt;td&gt;对象是元素为kv对的RDD，key保持不变，对value进行映射&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;一对一&lt;/td&gt;
&lt;td&gt;val b = rdd2.map(x =&amp;gt; (x.length, x)) &lt;br\&gt; b.mapValues(&amp;ldquo;x&amp;rdquo; + _ + &amp;ldquo;x&amp;rdquo;).collect&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;flatMap&lt;/td&gt;
&lt;td&gt;扁平化map后的结果，多个集合合并为一个集合&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;一对一&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;mapPartitions&lt;/td&gt;
&lt;td&gt;映射函数的参数为RDD中&lt;strong&gt;每一个分区&lt;/strong&gt;的迭代器&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;一对一&lt;/td&gt;
&lt;td&gt;可用于为RDD中数据按分区创建连接&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;reduce&lt;/td&gt;
&lt;td&gt;将RDD中元素两两传递给输入函数，产生一个新值，新产生的值与RDD中的下一个元素再被传递给输入函数，&lt;strong&gt;直到最后只有一个值为止&lt;/strong&gt;。&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;多对一&lt;/td&gt;
&lt;td&gt;rdd1.reduce((x,y) =&amp;gt; x+y) //结果为45&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;reduceByKey&lt;/td&gt;
&lt;td&gt;将key相同的元素的value进行reduce，组成一个新的KV对&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;多对一&lt;/td&gt;
&lt;td&gt;rdd3.reduceByKey((x,y) =&amp;gt; x+y).collect //结果为Array((1,2),(3,10))&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;filter&lt;/td&gt;
&lt;td&gt;对每个元素应用f函数，只保留返回值为true的元素&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;子集型&lt;/td&gt;
&lt;td&gt;val d = rdd3.filter{ case(x,y) =&amp;gt; equal(x,y) }.count() //结果为0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;sample&lt;/td&gt;
&lt;td&gt;对元素采样，获取子集&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;子集型&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;cache&lt;/td&gt;
&lt;td&gt;将元素从磁盘缓存到内存&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;cache型&lt;/td&gt;
&lt;td&gt;rdd1.cache()&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;persist&lt;/td&gt;
&lt;td&gt;对RDD缓存，位置可指定&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;cache型&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;([1-9]\d+|[2-9])
通常来讲，针对数据处理有几种常见模型，包括：&lt;r&gt;Iterative Algorithms&lt;/r&gt;,&lt;r&gt;Relational Queries&lt;/r&gt;,&lt;r&gt;MapReduce&lt;/r&gt;,&lt;r&gt;Stream Processing&lt;/r&gt;。例如Hadoop MapReduce采用了MapReduces模型，Storm则采用了Stream Processing模型。RDD混合了这四种模型，使得Spark可以应用于各种大数据处理场景。&lt;/p&gt;

&lt;p&gt;Spark将依赖分为narrow与wide。如果RDD的每个分区最多只能被一个Child RDD的一个分区使用，则称之为narrow dependency；若多个Child RDD分区都可以依赖，则称之为wide dependency。不同的操作依据其特性，可能会产生不同的依赖。例如map操作会产生narrow dependency，而join操作则产生wide dependency。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://ocwpxekrq.bkt.clouddn.com/rdd.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;上图说明了narrow和wide之间的区别。 narrow dependencies可以支持在同一个cluster node上以管道形式执行多条命令，而且它的失败恢复更有效，只需要重新计算丢失的parent partition即可；wide dependencies需要所有的父分区都是可用的，牵涉到RDD各级的多个Parent Partitions。&lt;/p&gt;

&lt;h3 id=&#34;共享变量&#34;&gt;共享变量&lt;/h3&gt;

&lt;p&gt;&lt;r&gt;broadcast&lt;/r&gt;变量：只读的共享变量 每个节点上都有一个拷贝。&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;val broadcastVar = sc.broadcast(&amp;quot;string test&amp;quot;) //broadcast variable is readonly
val v = broadcastVar.value
println(v)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;r&gt;accumulator&lt;/r&gt;变量：做累加器用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;val accum = sc.accumulator(0, &amp;quot;My Accumulator&amp;quot;) //value and name
sc.parallelize(1 to 1000000).foreach(x =&amp;gt; accum+= 1)
println(accum.name + &amp;quot;:&amp;quot; + accum.value)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;sparkcontext&#34;&gt;SparkContext&lt;/h3&gt;
</description>
    </item>
    
  </channel>
</rss>