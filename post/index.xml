<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Learn and record</title>
    <link>http://cherishzhang.github.io/post/</link>
    <description>Recent content in Posts on Learn and record</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Mar 2016 21:03:56 +0800</lastBuildDate>
    <atom:link href="http://cherishzhang.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Data Quality in Recommendation</title>
      <link>http://cherishzhang.github.io/post/paper/Data%20Quality%20in%20Recommendation/</link>
      <pubDate>Wed, 16 Mar 2016 21:03:56 +0800</pubDate>
      
      <guid>http://cherishzhang.github.io/post/paper/Data%20Quality%20in%20Recommendation/</guid>
      <description>

&lt;h2 id=&#34;data-quality-matters-in-recommender-systems:c7e7f190dc4ad9c3cea8a960f18951d1&#34;&gt;Data Quality Matters in Recommender Systems&lt;/h2&gt;

&lt;h3 id=&#34;摘要:c7e7f190dc4ad9c3cea8a960f18951d1&#34;&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;数据质量好坏在信息系统中是一个很重要的因素，但在推荐系统中考虑得却不是很多。比较常用的方法是ad-hoc式的清洗，如，去除数据集中的噪声和不可靠的记录。显露出的缺点是,没有结合数据集本身的特性。&lt;/p&gt;

&lt;p&gt;论文的主要贡献是考虑推荐系统中两个核心的数据质量问题：&lt;strong&gt;sparsity&lt;/strong&gt; 和 &lt;strong&gt;redundancy&lt;/strong&gt;。主要是设计了数据集相关的阈值模型和采样等级模型，然后在一系列的公开数据集上做了验证试验。&lt;/p&gt;

&lt;h3 id=&#34;具体方法:c7e7f190dc4ad9c3cea8a960f18951d1&#34;&gt;&lt;strong&gt;具体方法&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 id=&#34;关于数据的稀疏性:c7e7f190dc4ad9c3cea8a960f18951d1&#34;&gt;&lt;strong&gt;关于数据的稀疏性&lt;/strong&gt;&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;阈值模型(Threshold model)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;很多基于分数的推荐系统数据集中包含一部分&lt;strong&gt;冷启动&lt;/strong&gt;的用户和物品。一般的数据清洗操会去除这些用户和物品的打分信息。现实中的问题是，怎样得到最优的清洗阈值。最简单的暴力方法(brute-force)是评估所有可能的组合，但时间空间复杂度高，在实际中不可行。&lt;/p&gt;

&lt;p&gt;首先，明确目标:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The aim is to develop a heuristic method that predicts the optimal thresholds for a given user-item rating matrix, without building the model.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;然后，采用了一些合理的假设，如假设要预测的物品阈值是与&lt;strong&gt;物品向量&lt;/strong&gt;的平均长度&lt;code&gt;$\overline{r}_i$&lt;/code&gt;相关，在打分矩阵中，即为平均每个物品被打分的次数。由于推荐数据集中，只有一小部分的流行商品会被打分多次，大部分商品被打分的次数相对很少，这引入了模型的另外一个特征，即物品向量长度的&lt;strong&gt;power-law&lt;/strong&gt;分布,令H为物品向量长度的分布函数，拟合函数&lt;code&gt;$H=Ax^(-m)$&lt;/code&gt;,其中x是单个物品向量的长度，m是个正数。最终可以得到数据集对应的m参数值。m越大，长尾分布中的尾部越向下，反映到数据集上，就是更加少的物品被多次打分过，也就是说，m越大，数据集本身越稀疏。&lt;/p&gt;

&lt;p&gt;得到以上两个特征因素，接下来就是构建阈值模型，得到公式: &lt;code&gt;${IT}_d = \gamma*\frac{log(\overline{r}_i)}{m^2}$&lt;/code&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;评价方法&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;总共24个数据集，包括10个开放数据集，如Movielens, Million Songs, Flixster, Moviepilot, Filmtipset, Yelp, Yahoo! Music(broken down into albums, artists, and tracks), and BookCrossing。以及14个从公司或站点获取的专业数据集(proprietary)。&lt;/p&gt;

&lt;p&gt;每个数据集9-1划分成训练集和测试集，使用*Precision@K*作为衡量测试集的标准(K为测试集的总记录数)，10折交叉验证，平均准确率作为最后的得分。&lt;/p&gt;

&lt;p&gt;实验过程：
- 首先，寻找每个数据集d的最优IT值。具体对于某个IT值，过滤掉低于IT的item，对剩余数据进行矩阵分解(Matrix Factorization),建立推荐模型，并通过测试集评测模型的准确率。不断迭代，增长IT，寻找使得测试集准确率最高的IT作为最优阈值&lt;code&gt;${IT}^{opt}_d$&lt;/code&gt;，对应的准确率为&lt;code&gt;${P}^{opt}_d$&lt;/code&gt;。
- 接下来，对24个数据集采用leave-one-out交叉验证。在23个数据集上训练阈值模型，然后预测剩余数据集d的阈值&lt;code&gt;${IT}^{pred}_d$&lt;/code&gt;,并在过滤后的数据上训练推荐模型，计算准确率&lt;code&gt;$P^{pred}_d$&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;两个评测指标：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$NTE_d = |{IT}^{opt}_d - {IT}^{pred}_d|/{IT}^{opt}_d$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$AR_d = P^{pred}_d/P^{opt}_d$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;注：&lt;strong&gt;IT&lt;/strong&gt;(item threshold), &lt;strong&gt;AR&lt;/strong&gt;(accuracy ratio), &lt;strong&gt;NTE&lt;/strong&gt;(normalized threshold error)&lt;/p&gt;

&lt;p&gt;通过计算，&lt;code&gt;${NTE}_d$&lt;/code&gt;和&lt;code&gt;${AR}_d$&lt;/code&gt;之间的相关度为-0.54。这表明IT的误差越小，推荐模型的准确率越高。&lt;/p&gt;

&lt;h4 id=&#34;关于数据的冗余性:c7e7f190dc4ad9c3cea8a960f18951d1&#34;&gt;&lt;strong&gt;关于数据的冗余性&lt;/strong&gt;&lt;/h4&gt;

&lt;ol&gt;
&lt;li&gt;模型
数据集可以通过随机采样，建立模型，使得尽可能得与在全部数据上建立模型的结果相似。这对于实际中的大规模数据是有效的。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;模型目标：
   - The aim is to pick the &lt;strong&gt;loweset sampling rate&lt;/strong&gt; that will still result in the recommendation model as close as possible to the model that would have been built using the complete data.&lt;/p&gt;

&lt;p&gt;与阈值模型不同的是，在采样率的取值上没有最优。因为在全体数据上构建推荐模型总是最优的。&lt;/p&gt;

&lt;p&gt;定义&lt;code&gt;$SR$&lt;/code&gt;为采样数据的推荐结果与全体数据的推荐结果相似度不低于&lt;code&gt;$\Delta$&lt;/code&gt;时的最低采样率。&lt;/p&gt;

&lt;p&gt;定义&lt;code&gt;$U_d, I_d, R_d$&lt;/code&gt;为数据集d中的用户数量，商品数量，和打分项个数，给定采样率&lt;code&gt;$SR$&lt;/code&gt;,从所有用户中随机选取&lt;code&gt;$SR*U_d$&lt;/code&gt;个用户，在采样的数据集上建立推荐模型，对一个固定的测试集产生预测结果。比较与全部数据预测的结果差异。&lt;/p&gt;

&lt;p&gt;以对用户采样举例，假设数据的冗余性与三个因素相关a.用户数 b.打分矩阵的稀疏性 c.V-structure，得到公式：&lt;/p&gt;

&lt;p&gt;&lt;code&gt;${SR}_d = tanh(\frac{1}{{V-structure}_d * \sqrt{U_d} * \frac{R_d}{I_d * U_d}})$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;其中V-structure的定义为平均相似度之比，分子中的每对用户至少有一个打分项目相同，分母中的每对用户为全体用户的所有组合可能。&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;评价
采用19个专业数据集，90-10比例分训练集和测试集，10折交叉验证。实验主要验证了模型的合理性。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;我的思考:c7e7f190dc4ad9c3cea8a960f18951d1&#34;&gt;&lt;strong&gt;我的思考&lt;/strong&gt;&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;这篇论文提出了两个模型公式，并完成了实验验证。优点是模型公式与数据集本身的特性相关，不干涉推荐系统的建模过程。&lt;/li&gt;
&lt;li&gt;遗留下的问题：数据的稀疏性和冗余性只针对MF推荐模型，还可以扩展到与其他推荐模型相结合。&lt;/li&gt;
&lt;li&gt;考虑其他的评测指标，如覆盖率和多样性；同时，模型中还可以结合物品的内容属性和用户的位置属性。&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Telstra Network Disruptions</title>
      <link>http://cherishzhang.github.io/post/kaggle/Telstra/</link>
      <pubDate>Wed, 02 Mar 2016 21:03:56 +0800</pubDate>
      
      <guid>http://cherishzhang.github.io/post/kaggle/Telstra/</guid>
      <description>

&lt;h2 id=&#34;1-overview:43e8ca42a888262ca3ed3923385c58f2&#34;&gt;&lt;strong&gt;1. Overview&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;The goal of the &lt;a href=&#34;https://www.kaggle.com/c/telstra-recruiting-network/&#34;&gt;problem&lt;/a&gt; is to predict Telstr network&amp;rsquo;s fault severity at a time at a particular location based on the &lt;em&gt;log data&lt;/em&gt; available.&lt;/p&gt;

&lt;p&gt;The target has 3 categories:0,1,2. It&amp;rsquo;s a multiclass classification problems.Different types of features are extracted from log files and other sources: event_type.csv, log_feature.csv, resource_type.csv,severity_type.csv.&lt;/p&gt;

&lt;p&gt;My final score is &lt;em&gt;0.44917(72 of 974)&lt;/em&gt; in private leaderboard. Here are my &lt;a href=&#34;https://github.com/Cherishzhang/kaggle/tree/master/Telstra&#34;&gt;code&lt;/a&gt;, and I will record my solution.&lt;/p&gt;

&lt;h2 id=&#34;2-feature-engineer:43e8ca42a888262ca3ed3923385c58f2&#34;&gt;&lt;strong&gt;2. Feature Engineer&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Selecting and designing good features is an important area in machine learning, which is called &lt;em&gt;feature engineering&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;At First, I just merge all files on Id. Here are five type of features. they are location, severity_type, resource_type, event_type, log_feature.
location and severity_type are just one-to-one variables, and others are many_to_one variables.
There are about 1200 locations, some are only in the test set. The correlation between location variable and target is 0.27, it gave me a hint that neighbouring locations may be similar in the network&amp;rsquo;s fault severity problem. I used one_hot encode to solve the many_to_one features. So there are about 400+ features in the initial stage.&lt;/p&gt;

&lt;p&gt;I read a paper about how to preprocess high-cardinality Categorical attributes in classification and regression problems, but it seemed to bring little help. I will tried it again after the competition.&lt;/p&gt;

&lt;p&gt;On the forum, there are a heated discussion about the magic feature. I spent much of my time to find it.
It is the order of the same location in the severity file which follows the order of fault occurrence.It&amp;rsquo;s called &lt;em&gt;Intra-location order&lt;/em&gt;.&lt;br /&gt;
It really did a big help to the final score which improved almost 0.06. To each record, I compute the target(&lt;em&gt;fault_severity&lt;/em&gt;) probabilities from the previous same location records, and used the &lt;em&gt;previous-target_probabilities&lt;/em&gt; as a feature to build the model.&lt;/p&gt;

&lt;h2 id=&#34;3-build-models-and-ensembling:43e8ca42a888262ca3ed3923385c58f2&#34;&gt;&lt;strong&gt;3. Build models and Ensembling&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;I tried many models, decision tree, random forests, svm and xgboost. The xgboost model is performed well.
On ensembling, I just average the random forest and xgboost result as the final result.&lt;/p&gt;

&lt;h2 id=&#34;4-what-i-learned-from-other-kagglers:43e8ca42a888262ca3ed3923385c58f2&#34;&gt;&lt;strong&gt;4. What I learned from other kagglers&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;On the platform, kagglers are willing to share their ideas. Here are some valuable ideas on the &lt;a href=&#34;https://www.kaggle.com/c/telstra-recruiting-network/forums/t/19239/it-s-been-fun-post-your-code-github-links-here-after-the-competition&#34;&gt;Competition Forum&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;some-useful-tips-on-feature-engineering:43e8ca42a888262ca3ed3923385c58f2&#34;&gt;Some useful tips on feature engineering&lt;/h3&gt;

&lt;p&gt;It&amp;rsquo;s the most important step in machine learning whatever models you used.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;About location&lt;br /&gt;
&lt;em&gt;Similar location numbers have similar fault severity.(Treat the location as numeric.)&lt;/em&gt;
&lt;em&gt;Don&amp;rsquo;t one-hot-encode the location, Tree-based classifiers are not good at handling huge sparse feature matrix.&lt;/em&gt;
&lt;em&gt;Frequency of LogType_203 = 0 &amp;amp; LogType_203 &amp;gt;0 per location&lt;/em&gt;
&lt;em&gt;The records in log data are arranged in the order of time.(the magic feature)&lt;/em&gt; Here are two ways to encode
the information, One is for each location, use the row number, which starts from 1 to the total number of rows for that locaiton. The other
is to normalize it between 0 and 1.
&lt;em&gt;percentile transformation of location counts&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;About log feature&lt;br /&gt;
&lt;em&gt;Pattern of log feature&lt;/em&gt;
&amp;ldquo;one hot&amp;rdquo; encoding for all log features with volume &amp;gt; 0, for all rows.
Each &amp;ldquo;one hot&amp;rdquo; encoded pattern treated as a string.
Assigned integer ID to each to each string, used as feature.
The log transform for the count of &amp;ldquo;pattern of log feature&amp;rdquo;, the log transform for counts as &amp;ldquo;pattern of event&amp;rdquo;
and &amp;ldquo;pattern of resource&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Common categorical variables&lt;br /&gt;
&lt;em&gt;For high-cardinality categorical variables, frequency works well.(Add the frequency of each location in both train and test set.)&lt;/em&gt;
&lt;em&gt;Summary statistics to reduce one-to-many relationship to one-to-one, and two-way or more-way interaction among multiple variables.&lt;/em&gt;
&lt;em&gt;Meta features(using Logistic regression to fit sparse matrix as predictors, then ensemble the model).&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;A useful solution&lt;br /&gt;
&amp;gt;a.The order of id on log_feature was frozen.&lt;br /&gt;
&amp;gt;b.Converting location, log_feature into numbers and generating count, mean, sum, etc. features (feature set A)&lt;br /&gt;
&amp;gt;c.Feature B was generated by shifting A forward by 1 row&lt;br /&gt;
&amp;gt;d.Feature C was generated by shifting B backward by 1 row&lt;br /&gt;
&amp;gt;Combining A, B, and C and training xgb, RF, GBM models. My final model is an ensemble model of these models.&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>[ml] Intro</title>
      <link>http://cherishzhang.github.io/post/ml/Intro/</link>
      <pubDate>Wed, 02 Mar 2016 20:58:05 +0800</pubDate>
      
      <guid>http://cherishzhang.github.io/post/ml/Intro/</guid>
      <description>

&lt;h2 id=&#34;introduction:ad313508e3b44a067229577553308d3b&#34;&gt;Introduction&lt;/h2&gt;

&lt;h3 id=&#34;machine-learning:ad313508e3b44a067229577553308d3b&#34;&gt;Machine Learning&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Grew out of work in AI&lt;/li&gt;
&lt;li&gt;New capability for computers&lt;/li&gt;
&lt;li&gt;some examples:

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Database mining&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Large datasets from growth of automation/web.
&lt;strong&gt;Applications can&amp;rsquo;t program by hand&lt;/strong&gt;
&lt;strong&gt;Self-customizing programs&lt;/strong&gt;
E.g., product recommendations
&lt;strong&gt;Understanding human learning&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are two classes of machine learning, one is Supervised Learning, and other is Unsupervised Learning.&lt;/p&gt;

&lt;p&gt;For Supervised Learning which is given the &lt;strong&gt;right answers&lt;/strong&gt;. It include &lt;em&gt;regression&lt;/em&gt; and &lt;em&gt;classification&lt;/em&gt; problems,
  there are two examples: Housing price prediction, Breast cancer.&lt;/p&gt;

&lt;p&gt;For Unsupervised Learning&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>http://cherishzhang.github.io/post/paper/ideas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://cherishzhang.github.io/post/paper/ideas/</guid>
      <description>

&lt;h2 id=&#34;ideas:85616c9715bbdc812e16deb4b0c5527c&#34;&gt;ideas&lt;/h2&gt;

&lt;p&gt;下面列出我的一些想法：
learn2rank主要应用于信息检索领域，简单来说就是query-doc的排序问题。它的优点和缺点分别是：&lt;/p&gt;

&lt;p&gt;个性化推荐问题是对user-item对进行的一个排序。两者的结合之处和创新点在哪里。&lt;/p&gt;

&lt;p&gt;首先如果使用learn2rank进行个性化推荐策略，首先要提取出三类特征，用户特征，商品特征以及用户-商品交互特征。然后放入框架进行梯度下降，建立模型。&lt;/p&gt;

&lt;h2 id=&#34;recsys:85616c9715bbdc812e16deb4b0c5527c&#34;&gt;Recsys&lt;/h2&gt;

&lt;p&gt;了解到recsys2016的paper submit在4月13号前，如果自己想要投稿，那么必须在之前写好。
另外了解到&lt;a href=&#34;https://recsys.xing.com/team&#34;&gt;ACM RecSys Challenge 2016&lt;/a&gt;是关于一个职位推荐问题。&lt;a href=&#34;https://github.com/recsyschallenge/2016/blob/master/TrainingDataset.md&#34;&gt;data&lt;/a&gt; on github.
关于比赛：
任务是给定一个XING用户，推荐系统预测在下周用户会和哪个职位有互动。互动(interaction_type)分为三类：1(clicked) 2(bookmarked) 3(replied)。&lt;br /&gt;
训练集是关于XING网站数据的一个半合成(semi-synthetic)采样，主要是为了包括用户的隐私。里面包含一些智能用户，算法不能尝试去识别智能用户，也不能重构造flipped值。&lt;br /&gt;
数据集包括Impressions, Interactions, Users, Items和regions。
target_users.csv包含一些最终提交结果时需要预测的用户ID号。&lt;/p&gt;

&lt;p&gt;可以试一下svdfeature和learn2rank两个算法模型。由于数据集较大，程序运行时间过长，怎样才能减少运行时间。&lt;/p&gt;

&lt;p&gt;这两个选择其中之一。
这一个月的时间最好不要看一些娱乐相关的内容，重点搞推荐&lt;/p&gt;

&lt;h2 id=&#34;2016-3-13:85616c9715bbdc812e16deb4b0c5527c&#34;&gt;2016-3-13：&lt;/h2&gt;

&lt;p&gt;看之前recsys会议上发表过的论文。看一下learn2rank，svdfeature和新闻推荐之间可以产生联系否？
把learn2rank初步训练出的结果总结，发到周报中。&lt;/p&gt;

&lt;h3 id=&#34;2016-3-15:85616c9715bbdc812e16deb4b0c5527c&#34;&gt;2016-3-15:&lt;/h3&gt;

&lt;p&gt;添加反馈ctr特征到learn2rank中
观察首页中高点击率新闻的特征&lt;/p&gt;

&lt;h3 id=&#34;2016-5-16:85616c9715bbdc812e16deb4b0c5527c&#34;&gt;2016-5-16：&lt;/h3&gt;

&lt;p&gt;总结Recsys每年的论文种类。
Recsys 2015:
- papers:
- 1. content Driven User Profiling for Comment-Worthy Recommendations of News and Blog Articles.
- 2.&lt;/p&gt;

&lt;h2 id=&#34;short-paper:85616c9715bbdc812e16deb4b0c5527c&#34;&gt;- short paper:&lt;/h2&gt;

&lt;p&gt;Recsys 2014:&lt;/p&gt;

&lt;p&gt;Recsys 2013: &lt;br/&gt;
- keynote
- 1. Information Extraction, Sentiment analysis, and Recommendations
- 2. Online Advertising
- 3. Recommendation for Happiness&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>